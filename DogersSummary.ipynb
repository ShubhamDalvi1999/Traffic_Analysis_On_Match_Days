{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685394fa-b303-4bcf-a6ea-f6c40d57c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a8be07-7093-4e05-a39f-5d9f1906fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkSession.builder.appName(\"TrafficAnalysis\").master(\"local\").config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2975a1f-1a15-48ba-b1e8-49011247afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic =sc.read.text(\"Dodgers.data\")\n",
    "type(traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2f9a73-1d08-4a5f-bfa8-babe7bab44ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='4/10/2005 0:00,-1'),\n",
       " Row(value='4/10/2005 0:05,-1'),\n",
       " Row(value='4/10/2005 0:10,-1'),\n",
       " Row(value='4/10/2005 0:15,-1'),\n",
       " Row(value='4/10/2005 0:20,-1'),\n",
       " Row(value='4/10/2005 0:25,-1'),\n",
       " Row(value='4/10/2005 0:30,-1'),\n",
       " Row(value='4/10/2005 0:35,-1'),\n",
       " Row(value='4/10/2005 0:40,-1'),\n",
       " Row(value='4/10/2005 0:45,-1')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae303f-b089-4f28-8231-408577c7a0e2",
   "metadata": {},
   "source": [
    "**<h2>Using format and schema to interpret data file as csv </h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78c8122-23a2-4b42-8fc7-de68d9575264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema= StructType([StructField(\"timestamp\",StringType()),StructField(\"number_of_cars\",StringType())])\n",
    "\n",
    "traffic =sc.read.format(\"csv\").schema(schema).load(\"Dodgers.data\")\n",
    "type(traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82474985-a6c5-4a00-9882-af0e8327f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|     timestamp|number_of_cars|\n",
      "+--------------+--------------+\n",
      "|4/10/2005 0:00|            -1|\n",
      "|4/10/2005 0:05|            -1|\n",
      "|4/10/2005 0:10|            -1|\n",
      "|4/10/2005 0:15|            -1|\n",
      "|4/10/2005 0:20|            -1|\n",
      "+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traffic.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798c2f8-ff8f-4f38-be1a-27c5c7809257",
   "metadata": {},
   "source": [
    "**<h2>Infering schema as false and type casting column two</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4664a6a5-99af-42b9-94d3-a69ba977d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "games =sc.read.format(\"csv\").option(\"inferSchema\",\"false\").load(\"Dodgers.events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63b170e-32a4-4035-b949-17f0026228b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "traffic =traffic.withColumn(\"number_of_cars_i\", col(\"number_of_cars\").cast(\"int\")).drop(\"number_of_cars\")\n",
    "\n",
    "#traffic_by_time =traffic.groupBy(\"timestamp\").agg(sum(\"number_of_cars_i\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f818052a-7751-4aa4-b2cd-3b51889fef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- number_of_cars_i: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traffic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ddb21d-cd84-4594-9c8c-07840e4a23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "traffic_by_time = traffic.groupBy(\"timestamp\").agg(sum(\"number_of_cars_i\").alias(\"no_of_cars_per_time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d69d348-2980-44b3-a7d2-6d2434c3e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- no_of_cars_per_time: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traffic_by_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a779f8-9a35-4e1d-be05-2cdaea79a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|      timestamp|no_of_cars_per_time|\n",
      "+---------------+-------------------+\n",
      "| 7/14/2005 8:25|                 90|\n",
      "|7/15/2005 14:40|                 75|\n",
      "| 7/3/2005 23:40|                 72|\n",
      "| 7/14/2005 8:50|                 70|\n",
      "|8/26/2005 22:30|                 70|\n",
      "| 7/14/2005 9:05|                 70|\n",
      "| 7/3/2005 23:00|                 66|\n",
      "|4/13/2005 22:10|                 66|\n",
      "|8/14/2005 15:40|                 64|\n",
      "|5/13/2005 22:30|                 64|\n",
      "+---------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "traffic_by_time.sort(desc(\"no_of_cars_per_time\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e2307c-8063-4d36-89f4-16b02aef77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, date_format\n",
    "df_datetime = traffic_by_time.withColumn(\"datetime\", to_timestamp(\"timestamp\", \"MM/dd/yyyy HH:mm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ba9ea7-3ce9-43d8-814b-fc2b440d217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- no_of_cars_per_time: long (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482f1258-fd93-4707-9a1d-94d49380a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-------------------+\n",
      "|      timestamp|no_of_cars_per_time|           datetime|\n",
      "+---------------+-------------------+-------------------+\n",
      "| 4/10/2005 2:30|                 -1|2005-04-10 02:30:00|\n",
      "| 4/10/2005 3:00|                 -1|2005-04-10 03:00:00|\n",
      "| 4/10/2005 4:10|                 -1|2005-04-10 04:10:00|\n",
      "| 4/10/2005 8:20|                 -1|2005-04-10 08:20:00|\n",
      "|4/10/2005 11:00|                 -1|2005-04-10 11:00:00|\n",
      "| 4/11/2005 1:00|                 -1|2005-04-11 01:00:00|\n",
      "| 4/11/2005 3:20|                 -1|2005-04-11 03:20:00|\n",
      "|4/11/2005 12:30|                 32|2005-04-11 12:30:00|\n",
      "|4/12/2005 19:35|                 32|2005-04-12 19:35:00|\n",
      "|4/13/2005 11:10|                 25|2005-04-13 11:10:00|\n",
      "+---------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e298a9-1a9d-451d-9609-aa3a25e25887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datetime=df_datetime.drop(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fef8d656-042e-42fe-995d-f4e84b27eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- no_of_cars_per_time: long (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a1c7d12-9bb2-4798-a7e8-c84a727a56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|no_of_cars_per_time|           datetime|\n",
      "+-------------------+-------------------+\n",
      "|                 -1|2005-04-10 02:30:00|\n",
      "|                 -1|2005-04-10 03:00:00|\n",
      "|                 -1|2005-04-10 04:10:00|\n",
      "|                 -1|2005-04-10 08:20:00|\n",
      "|                 -1|2005-04-10 11:00:00|\n",
      "|                 -1|2005-04-11 01:00:00|\n",
      "|                 -1|2005-04-11 03:20:00|\n",
      "|                 32|2005-04-11 12:30:00|\n",
      "|                 32|2005-04-12 19:35:00|\n",
      "|                 25|2005-04-13 11:10:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0756368e-49f2-457c-bc2b-13e2499c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "df_datetime=df_datetime.withColumn(\"date\",  date_format(\"datetime\", \"MM/dd/yyyy\")).drop(\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed1d476-1217-4132-94c1-1c07326f188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- no_of_cars_per_time: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37c32cb4-f60b-4800-b111-0d029ffcf817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|no_of_cars_per_time|      date|\n",
      "+-------------------+----------+\n",
      "|                 -1|04/10/2005|\n",
      "|                 -1|04/10/2005|\n",
      "|                 -1|04/10/2005|\n",
      "|                 -1|04/10/2005|\n",
      "|                 -1|04/10/2005|\n",
      "|                 -1|04/11/2005|\n",
      "|                 -1|04/11/2005|\n",
      "|                 32|04/11/2005|\n",
      "|                 32|04/12/2005|\n",
      "|                 25|04/13/2005|\n",
      "+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a063f1-3fd2-44ce-b83a-6892c200e8eb",
   "metadata": {},
   "source": [
    "**<h2>Getting insights on cars per day</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ea4fc2-e421-4e4c-8431-3032e0eff718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,desc\n",
    "\n",
    "df_datetime=df_datetime.groupBy(\"date\").agg(sum(\"no_of_cars_per_time\").alias(\"cars_per_date\")).orderBy(desc(\"cars_per_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf708cf9-992c-409e-8692-62e81b9b5904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- cars_per_date: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce105627-c743-4031-8eb3-38fa4aff611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      date|cars_per_date|\n",
      "+----------+-------------+\n",
      "|07/28/2005|         7661|\n",
      "|07/29/2005|         7499|\n",
      "|08/12/2005|         7287|\n",
      "|07/27/2005|         7238|\n",
      "|09/23/2005|         7175|\n",
      "|07/26/2005|         7163|\n",
      "|05/20/2005|         7119|\n",
      "|08/11/2005|         7110|\n",
      "|09/08/2005|         7107|\n",
      "|09/07/2005|         7082|\n",
      "|09/30/2005|         7079|\n",
      "|08/10/2005|         7060|\n",
      "|07/22/2005|         7028|\n",
      "|08/05/2005|         6924|\n",
      "|09/29/2005|         6917|\n",
      "|07/25/2005|         6898|\n",
      "|09/09/2005|         6897|\n",
      "|09/16/2005|         6885|\n",
      "|09/28/2005|         6831|\n",
      "|04/12/2005|         6822|\n",
      "+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "320245d6-47fc-4a05-8372-96a751d8db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      date|cars_per_date|\n",
      "+----------+-------------+\n",
      "|04/10/2005|         -288|\n",
      "|10/01/2005|         -260|\n",
      "|06/28/2005|          -96|\n",
      "|07/04/2005|          328|\n",
      "|07/12/2005|         1204|\n",
      "|05/23/2005|         2173|\n",
      "|09/17/2005|         2426|\n",
      "|09/10/2005|         2851|\n",
      "|06/27/2005|         2907|\n",
      "|07/10/2005|         3518|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "df_datetime.orderBy(asc(\"cars_per_date\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283de134-8bd1-4677-90a4-171036953c43",
   "metadata": {},
   "source": [
    "**<h2>to remove the -ve values</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee4aaa6d-1a5e-43f0-8eed-5c5df7bb157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df_datetime_clean=df_datetime.withColumn(\"cars_per_date\", when(col(\"cars_per_date\") < 0, 0).otherwise(col(\"cars_per_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ce54de9-4e2a-495e-8d98-219fb98dd8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      date|cars_per_date|\n",
      "+----------+-------------+\n",
      "|06/28/2005|            0|\n",
      "|04/10/2005|            0|\n",
      "|10/01/2005|            0|\n",
      "|07/04/2005|          328|\n",
      "|07/12/2005|         1204|\n",
      "|05/23/2005|         2173|\n",
      "|09/17/2005|         2426|\n",
      "|09/10/2005|         2851|\n",
      "|06/27/2005|         2907|\n",
      "|07/10/2005|         3518|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime_clean.sort(asc(\"cars_per_date\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a41c43-d870-4e1a-bf7c-6c77b97a24ad",
   "metadata": {},
   "source": [
    "**<h2>Getting insights on cars per day and combining it with event day data</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ada1516-2d27-46f6-aa22-ca5397ecd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+-----+-------------+------+\n",
      "|     _c0|     _c1|     _c2|  _c3|          _c4|   _c5|\n",
      "+--------+--------+--------+-----+-------------+------+\n",
      "|04/12/05|13:10:00|16:23:00|55892|San Francisco|W 9-8�|\n",
      "|04/13/05|19:10:00|21:48:00|46514|San Francisco|W 4-1�|\n",
      "|04/15/05|19:40:00|21:48:00|51816|    San Diego|W 4-0�|\n",
      "|04/16/05|19:10:00|21:52:00|54704|    San Diego|W 8-3�|\n",
      "|04/17/05|13:10:00|15:31:00|53402|    San Diego|W 6-0�|\n",
      "|04/25/05|19:10:00|21:33:00|36876|      Arizona|L 4-2�|\n",
      "|04/26/05|19:10:00|22:00:00|44486|      Arizona|L 3-2�|\n",
      "|04/27/05|19:10:00|22:17:00|54387|      Arizona|L 6-3�|\n",
      "|04/29/05|19:40:00|22:01:00|40150|     Colorado|W 6-3�|\n",
      "|04/30/05|19:10:00|21:45:00|54123|     Colorado|W 6-2�|\n",
      "+--------+--------+--------+-----+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2beeecaa-b214-4945-bc2f-96bec08629cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "games= games.withColumn(\"date\", to_timestamp(\"_c0\", \"MM/dd/yy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ea54b95-cbfd-4085-9bce-5a2530355855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "games = games.withColumn(\"against\", col(\"_c4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46509d6-d60e-4fd5-92d7-f59702b0a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "games=games.select(\"date\",\"against\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d26f7433-98d6-45f6-8a8c-04e305171685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+\n",
      "|               date|      against|\n",
      "+-------------------+-------------+\n",
      "|2005-04-12 00:00:00|San Francisco|\n",
      "|2005-04-13 00:00:00|San Francisco|\n",
      "|2005-04-15 00:00:00|    San Diego|\n",
      "|2005-04-16 00:00:00|    San Diego|\n",
      "|2005-04-17 00:00:00|    San Diego|\n",
      "|2005-04-25 00:00:00|      Arizona|\n",
      "|2005-04-26 00:00:00|      Arizona|\n",
      "|2005-04-27 00:00:00|      Arizona|\n",
      "|2005-04-29 00:00:00|     Colorado|\n",
      "|2005-04-30 00:00:00|     Colorado|\n",
      "|2005-05-01 00:00:00|     Colorado|\n",
      "|2005-05-02 00:00:00|   Washington|\n",
      "|2005-05-03 00:00:00|   Washington|\n",
      "|2005-05-04 00:00:00|   Washington|\n",
      "|2005-05-13 00:00:00|      Atlanta|\n",
      "|2005-05-14 00:00:00|      Atlanta|\n",
      "|2005-05-15 00:00:00|      Atlanta|\n",
      "|2005-05-16 00:00:00|      Florida|\n",
      "|2005-05-17 00:00:00|      Florida|\n",
      "|2005-05-18 00:00:00|      Florida|\n",
      "+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ffea547-b37e-4f3c-a9e4-0d721fbee900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|      against|    date_m|\n",
      "+-------------+----------+\n",
      "|San Francisco|12/04/2005|\n",
      "|San Francisco|13/04/2005|\n",
      "|    San Diego|15/04/2005|\n",
      "|    San Diego|16/04/2005|\n",
      "|    San Diego|17/04/2005|\n",
      "|      Arizona|25/04/2005|\n",
      "|      Arizona|26/04/2005|\n",
      "|      Arizona|27/04/2005|\n",
      "|     Colorado|29/04/2005|\n",
      "|     Colorado|30/04/2005|\n",
      "|     Colorado|01/05/2005|\n",
      "|   Washington|02/05/2005|\n",
      "|   Washington|03/05/2005|\n",
      "|   Washington|04/05/2005|\n",
      "|      Atlanta|13/05/2005|\n",
      "|      Atlanta|14/05/2005|\n",
      "|      Atlanta|15/05/2005|\n",
      "|      Florida|16/05/2005|\n",
      "|      Florida|17/05/2005|\n",
      "|      Florida|18/05/2005|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, date_format\n",
    "games= games.withColumn(\"date_m\", date_format(\"date\",\"dd/MM/yyy\")).drop(\"date\")\n",
    "games.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "380d7e3d-39c0-4d63-8825-0070fd41dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.withColumn(\"date\", col(\"date_m\")).drop(\"date_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b897d6c-7ad9-4b9d-85c3-efedda914f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- against: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa94d074-f821-4c38-954e-576519e3f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyTrendCombined = df_datetime_clean.join(games, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a22c8-a315-47ac-a53c-626ecfa29b95",
   "metadata": {},
   "source": [
    "**<h2>Creating new column with day name based on the against column</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89cac8cc-88d7-491a-91b5-c6cea6fff849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dailyTrendCombined = dailyTrendCombined.withColumn(\"day\", when(col(\"against\").isNull()\n",
    "                                                               , \"Regular Day\").otherwise(\"Match Day\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82453b0-31b7-4386-91ce-d4eabdd0569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyTrendCombined.select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d2e4a97-8d61-4451-82ef-53125dda5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-------+---+\n",
      "|date|cars_per_date|against|day|\n",
      "+----+-------------+-------+---+\n",
      "+----+-------------+-------+---+\n",
      "only showing top 0 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dailyTrendCombined.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be66154d-6714-4960-8232-882e6761af82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendCombined.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd82b0-78b8-4eea-9588-fc5013d61eff",
   "metadata": {},
   "source": [
    "**Combine by key on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "124efc7f-289e-422c-9d34-27c89e93c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "avg_score = dailyTrendCombined.groupBy(\"day\").agg(avg(\"cars_per_date\").alias(\"avg_cars_on\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "640ab48b-e94c-4ccc-9829-0ccef5c58108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|        day|      avg_cars_on|\n",
      "+-----------+-----------------+\n",
      "|  Match Day|6063.111111111111|\n",
      "|Regular Day|5642.036144578313|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5f9e4-02b9-45b2-aea7-9813718d4845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
